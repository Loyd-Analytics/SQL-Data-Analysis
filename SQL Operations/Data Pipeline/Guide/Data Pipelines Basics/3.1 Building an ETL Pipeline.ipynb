{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building an ETL Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ready to ratchet up the fun? In this exercise, you'll be responsible for building the rest of the load() function before running each step in the ETL process. The extract() and transform() functions have been defined for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "- Complete the load() function by writing the transformed_data DataFrame to a .csv file, using file_name.\n",
    "- Use the transform() function to clean the extracted_data DataFrame.\n",
    "- Load transformed_data to the transformed_data.csv file using the load() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data_frame, file_name):\n",
    "  # Write cleaned_data to a CSV using file_name\n",
    "  data_frame.to_csv(file_name)\n",
    "  print(f\"Successfully loaded data to {file_name}\")\n",
    "\n",
    "extracted_data = extract(file_name=\"raw_data.csv\")\n",
    "\n",
    "# Transform extracted_data using transform() function\n",
    "transformed_data = transform(data_frame=extracted_data)\n",
    "\n",
    "# Load transformed_data to the file transformed_data.csv\n",
    "load(data_frame=transformed_data, file_name=\"transformed_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracting data from a source system\n",
    "Transformed the raw data returned from extract()\n",
    "Successfully loaded data to transformed_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- This code snippet demonstrates a simple data processing pipeline. \n",
    "- It first extracts data from a CSV file (raw_data.csv), transforms it using a transform function (not shown), and then saves the transformed data to another CSV file (transformed_data.csv). \n",
    "- The load function handles the saving process, printing a success message. \n",
    "- Note that there's a bug in the load function; it always saves to cleaned_data.csv regardless of the file_name argument. \n",
    "- It should be corrected to use file_name instead of a hardcoded filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The \"T\" in ELT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's not forget about ELT! Here, the extract() and load() functions have been defined for you. Now, all that's left is to finish defining the transform() function and run the pipeline. Go get 'em!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "- Update the transform() function to call the .execute() method on the data_warehouse object.\n",
    "- Use the newly-updated transform() function to populate data in the total_sales target table by transforming data in the raw_sales_data source table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete building the transform() function\n",
    "def transform(source_table, target_table):\n",
    "  data_warehouse.execute(f\"\"\"\n",
    "  CREATE TABLE {target_table} AS\n",
    "      SELECT\n",
    "          CONCAT(\"Product ID: \", product_id),\n",
    "          quantity * price\n",
    "      FROM {source_table};\n",
    "  \"\"\")\n",
    "\n",
    "extracted_data = extract(file_name=\"raw_sales_data.csv\")\n",
    "load(data_frame=extracted_data, table_name=\"raw_sales_data\")\n",
    "\n",
    "# Populate total_sales by transforming raw_sales_data\n",
    "transform(source_table=\"raw_sales_data\", target_table=\"total_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "Extracted data from file storage.\n",
    "Loading extracted data to sale_items.\n",
    "Ran the query: \n",
    "  CREATE TABLE total_sales AS\n",
    "      SELECT\n",
    "          CONCAT(\"Product ID: \", product_id),\n",
    "          quantity * price\n",
    "      FROM raw_sales_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extracting, Transforming, and Loading Student Scores Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alright, it's time to build your own ETL pipeline from scratch. In this exercise, you'll build three functions; extract(), transform(), and load(). Then, you'll use these functions to run your pipeline.\n",
    "  \n",
    "  The pandas library has been imported as pd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "- In the extract() function, use the appropriate pandas function to read a CSV into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "  # Read a CSV with a path stored using file_name into memory\n",
    "  return pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "- Update the transform() function to filter the data_frame to only include the columns industry_name and number_of_firms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "  return pd.read_csv(file_name)\n",
    "\n",
    "def transform(data_frame):\n",
    "  # Filter the data_frame to only incude a subset of columns\n",
    "  return data_frame.loc[:, [\"industry_name\", \"number_of_firms\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "- In the load() function write the data_frame to a path stored using the parameter file_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "  return pd.read_csv(file_name)\n",
    "\n",
    "def transform(data_frame):\n",
    "  return data_frame.loc[:, [\"industry_name\", \"number_of_firms\"]]\n",
    "\n",
    "def load(data_frame, file_name):\n",
    "  # Write the data_frame to a CSV\n",
    "  data_frame.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "- Pass the transformed_data DataFrame to the load() function, and run the ETL pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "  return pd.read_csv(file_name)\n",
    "\n",
    "def transform(data_frame):\n",
    "  return data_frame.loc[:, [\"industry_name\", \"number_of_firms\"]]\n",
    "\n",
    "def load(data_frame, file_name):\n",
    "  data_frame.to_csv(file_name)\n",
    "  \n",
    "extracted_data = extract(file_name=\"raw_industry_data.csv\")\n",
    "transformed_data = transform(data_frame=extracted_data)\n",
    "\n",
    "# Pass the transformed_data DataFrame to the load() function\n",
    "load(data_frame=transformed_data, file_name=\"number_of_firms.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
