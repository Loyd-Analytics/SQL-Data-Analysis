{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Working with APIs and JSON data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An API, or application programming interface, is software that allows data consumers to send or receive data, without directly accessing the database in which information is stored. \n",
    "- APIs are one of the most commonly-used tools to gather data from third parties. \n",
    "- Working with an API is like going to a bank. In a single trip, you can deposit or withdraw money, or both. \n",
    "- The bank won't let you directly interact with their bank vault, but it allows for specially-trained individuals to do so. \n",
    "- This is just like an API, which prevents a user from directly interacting with a database. \n",
    "- Most APIs only allows for users to read data, to prevent accidental deletions or overwriting of data. \n",
    "- APIs typically serve data in JSON format, which stands for JavaScript object notation. \n",
    "- JSON data is non-tabular, and stores information in key-value pairs. JSON data is schema-less, and looks and feels quite similar to dictionaries in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API (Application Programming Interface)\n",
    "- Software that sits on top of data sources\n",
    "- Prevents direct interaction with database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON (JavaScript Object Notation)\n",
    "- Key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"key\": \"value\",\n",
    "  \"open\": 0.121875\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reading JSON files with pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data structure above depicts data in JSON format, containing four key-value pairs. Each key stores a list of values, column-wise. \n",
    "- To extract data from a JSON file in this format, we'll use the pd-dot-read_json function, which returns a DataFrame. \n",
    "- The first argument passed to read_json is the file_path the JSON file is stored at. \n",
    "- The orient parameter denotes how data is stored in the JSON file. \n",
    "- Here, the data is stored in a columnar manner, with each key-value pair corresponding to column headers and values. \n",
    "- When data is stored as a list of dictionaries, orient should be set to \"records\". \"index\" is passed to orient when key-value pairs are made up of indicies and a dictionary containing the remainder of the record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"timestamps\": [863703000, 863789400, ...],\n",
    "  \"open\": [0.121875, 0.098438, ...],\n",
    "  \"close\": [...],\n",
    "  \"volume\": [...]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the  `.read_json()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a JSON file in the format above\n",
    "raw_stock_data = pd.read_json(\"raw_stock_data.json\", orient=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Nested or unstructured JSON data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes, data stored in a JSON file is not \"DataFrame-ready\". \n",
    "- This might be the case when the source data contains nested objects or has a varying schema, as shown here. \n",
    "- When this occurs, the best approach is to first load the file into a dictionary, with the intent to transform the data into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is not always DataFrame-ready\n",
    "- Nested objects\n",
    "- Varying \"schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"863703000\": {\n",
    "    \"volume\": 1443120000,\n",
    "    \"price\": {\n",
    "      \"close\": 0.09791,\n",
    "      \"open\": 0.12187\n",
    "    }\n",
    "  },\n",
    "  \"863789400\": {\n",
    "     ... \n",
    "  }, ... \n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reading JSON files with json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To do this, we'll use the load function, from the json library. \n",
    "- This function takes a file object, and returns a Python data type, typically a dictionary. \n",
    "- In our example, we call the json-dot-load function on the file object to extract the contents of the file into the raw_stock_data variable. \n",
    "- Using the type function we see that raw_stock_data is indeed a dictionary. \n",
    "- This dictionary should look nearly identical to the contents of the JSON file. \n",
    "- Best of all, we can transform this dictionary into a format such that it can be easily stored as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"raw_stock_data.json\", \"r\") as file:\n",
    "    # Load the file into a dictionary\n",
    "    raw_stock_data = json.load(file)\n",
    "\n",
    "    # Confirm the type of the raw_stock_data variable\n",
    "    print(type(raw_stock_data))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
